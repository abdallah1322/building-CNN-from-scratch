{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "J5DEUuWLruJ9"
      },
      "source": [
        "<h1><center>- Assignment 3 -</center></h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oRG5_RoaruKX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aHY091VUruKa"
      },
      "source": [
        "#### 1. Load MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WBmkJzGqruKb"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('mnist_train.csv')\n",
        "test_data = pd.read_csv('mnist_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "quGV_u1EfGtV"
      },
      "outputs": [],
      "source": [
        "s1 = train_data.sample(n = 1000)\n",
        "s2 = test_data.sample(n = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mDwb9ToaruKc"
      },
      "outputs": [],
      "source": [
        "train_features = s1.drop(['label'], axis=1)\n",
        "train_labels = s1['label']\n",
        "\n",
        "test_features = s2.drop(['label'], axis=1)\n",
        "test_labels = s2['label']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PpBVxe9KruKd"
      },
      "source": [
        "#### 2. Standardize your dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "op3x-hA-ruKe"
      },
      "outputs": [],
      "source": [
        "train_features = (train_features - np.mean(train_features, axis=0)) / np.std(train_features, axis=0)\n",
        "train_features = train_features.fillna(0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pveBED3NruKf"
      },
      "source": [
        "#### 3. Divide data into training and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Q8BaFKgrruKf"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "n72O-u_SruKh"
      },
      "source": [
        "#### 4. Apply one hot vector for labels (meaning the value is 1 in the correct class and 0 in the rest, there will be 10 classes so a vector of 10)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-WWxBMyc5r1h"
      },
      "source": [
        "creates a zero-filled NumPy array with a shape of (n_samples, n_classes), where n_samples is the number of samples in the y_train array and n_classes is the maximum value in the y_train array plus one.\n",
        "\n",
        "y_train is an array of labels with values 0 and 1, the y_train_one_hot array will have a shape of (n_samples, 2).\n",
        "\n",
        "assign a value of 1 to the corresponding element in each row of the y_train_one_hot array based on the value in the corresponding element of the y_train array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Qx2XWEDanMEe"
      },
      "outputs": [],
      "source": [
        "y_train_one_hot = np.zeros((y_train.size, y_train.max()+1))\n",
        "y_train_one_hot[np.arange(y_train.size), y_train] = 1\n",
        "\n",
        "y_test_one_hot = np.zeros((y_test.size, y_test.max()+1))\n",
        "y_test_one_hot[np.arange(y_test.size), y_test] = 1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XTT1tCRQruKj"
      },
      "source": [
        "#### 5. Implement a dynamic Neural Network from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "G7A-VA03yVau"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, learning_rate = 0.1, epochs = 1000):\n",
        "        self.weights = []\n",
        "        self.bias = []\n",
        "        self.lr = learning_rate\n",
        "        self.epochs = epochs\n",
        "        pass\n",
        "\n",
        "    # Activation function\n",
        "    def sigmoid(self, x):\n",
        "        return np.piecewise(x, [x > 0],[lambda i: 1 / (1 + np.exp(-i)), lambda i: np.exp(i) / (1 + np.exp(i))],)\n",
        "\n",
        "    def sigmoid_derivative(self, a):\n",
        "        return np.dot(a.T, (1-a))\n",
        "\n",
        "    # Loss function\n",
        "    def MSE(self, y_actual, y_pred):\n",
        "        return np.mean((y_pred - y_actual) ** 2)\n",
        "\n",
        "    def MSE_derivative(self, y_actual, y_pred):\n",
        "        return y_pred - y_actual\n",
        "\n",
        "    # Dynamic neural network function\n",
        "    def NN(self, x, y, num_of_layers, size_of_layers):\n",
        "        samples, features = x.shape\n",
        "        dim = features\n",
        "\n",
        "        # Initialize the weights and bias of the layers with random values\n",
        "        for layer in range(num_of_layers):\n",
        "            self.weights.append(np.random.randn(size_of_layers[layer], dim))\n",
        "            self.bias.append(np.random.randn(size_of_layers[layer]))\n",
        "            dim = np.shape(self.weights[layer])[0]\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            A = []\n",
        "            X = x\n",
        "\n",
        "            # Forward propagation\n",
        "            for i in range(num_of_layers):\n",
        "                z = np.dot(X, np.transpose(self.weights[i])) + self.bias[i]\n",
        "                a = self.sigmoid(z)\n",
        "                A.append(a.T)\n",
        "                X = a\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = self.MSE(A[-1], y)\n",
        "\n",
        "            # Backpropagation\n",
        "            dz = 1\n",
        "            for j in range(num_of_layers - 1, -1, -1):\n",
        "\n",
        "                if j - 1 >= 0: X = A[j - 1]\n",
        "                else: X = x.T\n",
        "\n",
        "                if j == num_of_layers - 1:    # Output Layer\n",
        "                    dz = dz * self.MSE_derivative(A[-1], y)\n",
        "                else:                         # Hidden Layer\n",
        "                    dz = np.dot(dz.T, self.weights[j + 1]).T\n",
        "                dz = np.dot(dz, self.sigmoid_derivative(A[j]))\n",
        "                dw = np.dot(dz, X.T)\n",
        "\n",
        "                # update weights\n",
        "                self.weights[j] -= (dw * self.lr) / size_of_layers[j]\n",
        "\n",
        "                # update bias\n",
        "                for k in range(len(self.bias[j])):\n",
        "                    self.bias[j][k] -= (np.mean(dz[k]) * self.lr)\n",
        "\n",
        "    # Test function\n",
        "    def test(self, X_test, num_of_layers):\n",
        "        a = X_test\n",
        "        for i in range(num_of_layers):\n",
        "            z = np.dot(a, np.transpose(self.weights[i])) + self.bias[i]\n",
        "            a = self.sigmoid(z)\n",
        "            \n",
        "        a = np.transpose(a)\n",
        "        return a\n",
        "    \n",
        "    # Accuracy function\n",
        "    def calculate_accuracy(self, y_pred, y_test_one_hot):\n",
        "        true_labels = np.argmax(y_pred, axis=1)\n",
        "        return np.mean(true_labels == y_test_one_hot)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JTPaFUZtruKs"
      },
      "source": [
        "#### 7. Test your code with the following architectures and report your different accuracies for each case from the following:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8tmQAJtDruKt"
      },
      "source": [
        "- 1.  Build NN with only 2 layers => 1 hidden layer and 1 output layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFh1YagdruKt",
        "outputId": "003069e5-b9d9-46aa-eb66-a0b06721170b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy with 2 layers: 90.00%\n"
          ]
        }
      ],
      "source": [
        "case_1 = NeuralNetwork()\n",
        "case_1.NN(X_train, y_train_one_hot.T, 2, [2,10])\n",
        "y_pred = case_1.test(X_test, 2)\n",
        "accuracy = case_1.calculate_accuracy(y_pred , y_test_one_hot)\n",
        "print('Accuracy with 2 layers: {:.2f}%'.format(accuracy * 100))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lV_8kB54ruKu"
      },
      "source": [
        "- 2. Build NN with 3 layers=> 2 hidden layers Where # of neurons in first layer < # of neurons in second layer and 1 output layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM9g8EKhruKv",
        "outputId": "22bff5e6-c10c-4f3f-b384-ab5d512db16b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy with 3 layers (neurons in first layer < neurons in second layer): 90.00%\n"
          ]
        }
      ],
      "source": [
        "case_2 = NeuralNetwork()\n",
        "case_2.NN(X_train, y_train_one_hot.T, 3, [20, 40, 10])\n",
        "y_pred = case_2.test(X_test, 3)\n",
        "accuracy = case_2.calculate_accuracy(y_pred , y_test_one_hot)\n",
        "print('Accuracy with 3 layers (neurons in first layer < neurons in second layer): {:.2f}%'.format(accuracy * 100))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Lrr_SdG0ruKv"
      },
      "source": [
        "- 3. Build NN with 3 layers=> 2 hidden layers Where # of neurons in first layer > # of neurons in second layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUwMUNPJruKw",
        "outputId": "52df9b65-41ff-40cf-a515-0e7867dd5737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy with 3 layers (neurons in first layer > neurons in second layer): 90.00%\n"
          ]
        }
      ],
      "source": [
        "case_3 = NeuralNetwork()\n",
        "case_3.NN(X_train, y_train_one_hot.T, 3, [40, 20, 10])\n",
        "y_pred = case_3.test(X_test, 3)\n",
        "accuracy = case_3.calculate_accuracy(y_pred , y_test_one_hot)\n",
        "print('Accuracy with 3 layers (neurons in first layer > neurons in second layer): {:.2f}%'.format(accuracy * 100))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
